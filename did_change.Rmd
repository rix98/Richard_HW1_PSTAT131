---
title: "Homework 1"
author: "Richard Antony"
date: '2022-09-27'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


**Question 1:**

**Define supervised and unsupervised learning. What are the difference(s) between them?**

The definition of supervised learning is that input and ouput are given. In supervised learning we can also have the output that we predict to be crosscheck with . In this case doing the model on a train data and then comparing it on the test data. The actual observation of the data is the supervisor in supervised learning.

The definiton of unsupervised learning means that we have nothing to be crosscheck with . It has no response and only labelled inut. Unsupervised learning is mostly use to know the realtions between its data itself and to see unseen trends. Unsupervised learning are trained using unlabeled data.

Differences:

Supervised learning can be categorized to classifiction and regression while unsupervised learning is classifed to clustering and associations problems.

Supervised learning have labelled inputs and outputs while unsupervised learning only has labelled inputs. This makes supervised learning model outputs cross checkable

**Question 2:**

**Explain the difference between a regression model and a classification model, specifically in the context of machine learning.**

Regression model is used when your output you want to predict is continuous. There are many types of regression in machine learning base how many features you use and what assumptions must be assume in the model( EX: linear or non-linear relationship).Usually the output is numerical (quantitative). Types of regression are linear regression, multiple regression, polynomial regression.

Classification model is used when the output you want to predict is discrete or categorical.Output is qualitative. Types of classicfication model inclde tree models, random forest and K-nearest neighbour.

**Question 3**

**Name two commonly used metrics for regression ML problems. Name two commonly used metrics for classification ML problems.**

2 commnonly used metrics for regression ML problems are : MSE(Mean Squared Error) and R-Square(goodness of fit).
2 commonly used metrics for classification ML problems are: accuracy and precision

**Question 4:**

**As discussed, statistical models can be used for different purposes. These purposes can generally be classified into the following three categories. Provide a brief description of each.**

Descriptive models: Visual test. Choose model that best visually highlight a trend in a data. Examples can be using a line from scaterrplot . 

Inferential models: To predict the response/output with minimum reducible error.Find which and what mixtures of features fits best the model. Does not rely on hypothesis testing.

Predictive models: See which features are significant in the model. Objective is to test theories. Able to state relationship between response and predictors.

From 'https://gauchospace.ucsb.edu/courses/pluginfile.php/8942693/mod_resource/content/2/day_1_131_231.pdf' page 39.


**Question 5:**

**Predictive models are frequently used in machine learning, and they can usually be described as either mechanistic or empirically-driven. Answer the following questions.**

**Define mechanistic. Define empirically-driven. How do these model types differ? How are they similar?**

Mechanistic model means using theory to predict the future. Empirically-driven model uses real-world data ,metrics to predict the future. They both are similar as their objective are to predict the future.

Mechanistic definition = 'relating to theories which explain phenomena in purely physical or deterministic terms.'
quote from: Oxford Languages

Empirically-driven= 'in a way that is provable or verifiable by experience or experiment'
quote from: ' https://www.dictionary.com/browse/empirically#:~:text=adverb%20in%20a%20way%20that%20is%20based%20on,for%20future%20empirically%20grounded%20research%20and%20policy%20analysis'

**In general, is a mechanistic or empirically-driven model easier to understand? Explain your choice.**

I would say Mechanistic model is easier to understand . Mechanistic model are based on theories and they assume a parametric form. Empircally-driven model are base on real world data , which can be very messy most times. Empirically-driven model is non parametric and more flexible than mechanistic.

**Describe how the bias-variance tradeoff is related to the use of mechanistic or empirically-driven models.**

More bias , less variance . Less bias more variance. The bias-variance tradeoff is related to the use of mechanistic or empirically-driven models because bias-variacne tradeoff can tell you the prediction error. How accurate is the model? I think if its for mechanistic model the bias variance trade off is related to the assumptions of the model . Fewer assumptions can produce low bias or More assumptions can produce high bias. 
Balancing the bias variance trade off can also reduce over fitting or under fitting. This can be use to mechanistic or empirically-driven models.

**Question 6:**

**A political candidate’s campaign has collected some detailed voter history data from their constituents. The campaign is interested in two questions:**

**Given a voter’s profile/data, how likely is it that they will vote in favor of the candidate?**

This is Predictive. A voters profile/data is a combination of features .It wants to find the combination of feauters that a voter has that would likely to favor the candidate. It does not focus on hypothesis test.

**How would a voter’s likelihood of support for the candidate change if they had personal contact with the candidate?**

This is Inferential. This question is testing a feature significant to the outcome and the feature is "  if they had personal contact with the candidate " . This then can state the predictor "had personal contact with the candidate" with the outcome " support for the candidate".

**Classify each question as either predictive or inferential. Explain your reasoning for each.**


**Exploratory Data Analysis**
**This section will ask you to complete several exercises. For this homework assignment, we’ll be working with the mpg data set that is loaded when you load the tidyverse. Make sure you load the tidyverse and any other packages you need.**

**Exploratory data analysis (or EDA) is not based on a specific set of rules or formulas. It is more of a state of curiosity about data. It’s an iterative process of:**

**generating questions about data**

**visualize and transform your data as necessary to get answers**

**use what you learned to generate more questions**

**A couple questions are always useful when you start out. These are “what variation occurs within the variables,” and “what covariation occurs between the variables.”**

 
**You should use the tidyverse and ggplot2 for these exercises.**

```{r}
#Run packages
library(tidyverse)
library(ggplot2)
```

**Exercise 1:**
**We are interested in highway miles per gallon, or the hwy variable. Create a histogram of this variable. Describe what you see/learn.** 
```{r}

#hist(mpg$hwy)
ggplot(mpg,aes(x=hwy)) + geom_histogram(bins=7,fill='steelblue', col='black') 

```
#See that the histogram for hwy is right skewed . This can be that hwy is not normally distributed. The frequency is highest when the hwy is around 25-30 .


#Exercise 2:
#Create a scatterplot. Put hwy on the x-axis and cty on the y-axis. Describe what you notice. Is there a relationship between hwy and cty? What does this mean?

```{r}

ggplot(mpg,aes(x=hwy,y=cty)) + geom_point(col='darkred')
```
# Yes there is a linear relationship between hwy and cty . As hwy increases , cty increases . Can be that this 2 features have a positive correlation.



#Exercise 3:
#Make a bar plot of manufacturer. Flip it so that the manufacturers are on the y-axis. Order the bars by height. Which manufacturer produced the most cars? Which produced the least?

```{r}
library(dplyr)
library(ggplot2)
library(tidyverse)
manufac<-mpg %>% group_by(manufacturer) %>%  summarise(frequ=n()) %>% arrange(-frequ)
#manufac

  manufac %>% 
    ggplot(aes(fct_reorder(manufacturer,
                           frequ), 
               frequ))+
    geom_col() + labs(x="Manufacturer",y="Frequency", title="Number of Manufactures") + coord_flip() 
    
```
# Manufacture that produced the most cars is dodge and the least is lincoln.

#Exercise 4:
#Make a box plot of hwy, grouped by cyl. Do you see a pattern? If so, what?

```{r}
# load library ggplot
library(ggplot2)
  
# Plot boxplot using ggplot function
plot <- ggplot(mpg, aes(x=factor(cyl), y=hwy))+
     geom_boxplot()
 
# print boxplot
plot
```
# Yes there is a pattern , as the cyl increase hwy decreases . We can see the boxplot median from left to right decreases.



#Exercise 5:
#Use the corrplot package to make a lower triangle correlation matrix of the mpg dataset. (Hint: You can find information on the package here.)

#Which variables are positively or negatively correlated with which others? Do these relationships make sense to you? Are there any that surprise you?

```{r}
library(dplyr)
library(corrplot)
#h<-cor(mpg)

#mpg_num<-mpg %>% dplyr::select_if(is.numeric)

?select_if
mpg %>% 
  select_if(is.numeric) %>% cor() %>% corrplot(method='number',type='lower')
```

**Cyl with displ have 0.93 postive correlation**

**Cty with displ have -0.8 correlation** 

**hwy and displ have -0.77 correlation**

**Cty with Cyl have -0.81 correlation**

**hwy and cyl have -0.76 correlation**

**The relation ship makes sense to me, none surprise me **




